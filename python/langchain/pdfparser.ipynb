{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbaaf7af-aee1-41df-9ce4-ef7903e05ea5",
   "metadata": {},
   "source": [
    "# PDF to markdown \n",
    "pip install pypdf pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245caa33-2504-4462-9280-113123536fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_to_markdown.py\n",
    "import os, sys, pathlib\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45183d0d-03e0-4e5b-ae21-9fc83910bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_path: /home/santy/programming/python/langchain/mypdf.pdf out_path: /home/santy/programming/python/langchain/mypdf.md\n"
     ]
    }
   ],
   "source": [
    "in_path = pathlib.Path(\"mypdf.pdf\").expanduser().resolve()\n",
    "out_path = pathlib.Path(\"mypdf.md\").expanduser().resolve()\n",
    "print(f\"in_path: {in_path} out_path: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d98bd19-3f3a-46f9-a644-34079c57045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1) Load PDF -> LangChain Documents (page-level)\n",
    "    loader = PyMuPDFLoader(str(in_path))\n",
    "    docs = loader.load()  # one Document per page (metadata includes page number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1abefb5-9fe0-48ca-963b-56ad8892e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 2) Split into LLM-sized chunks (preserve some context)\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=4000,\n",
    "        chunk_overlap=300,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f28df95-fb4c-4307-8fa4-f7c929f16262",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 3) Define the Markdown conversion chain\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You convert raw PDF-extracted text into clean, readable Markdown.\\n\"\n",
    "         \"Rules:\\n\"\n",
    "         \"- Keep headings (#, ##, ###) based on apparent structure.\\n\"\n",
    "         \"- Preserve lists, bullet points, and numbering.\\n\"\n",
    "         \"- Keep code blocks and inline code when obvious.\\n\"\n",
    "         \"- For tables, reconstruct using Markdown tables when possible; otherwise use list blocks.\\n\"\n",
    "         \"- Remove page headers/footers, page numbers, and junk artifacts.\\n\"\n",
    "         \"- Never invent content; only reformat what’s present.\"),\n",
    "        (\"user\",\n",
    "         \"Source text (partial):\\n\\n{chunk}\\n\\n\"\n",
    "         \"Return ONLY Markdown for that text, no preface, no explanations.\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee08183a-098b-474c-addd-e09f2bb43d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# build your agent\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",            # Use a lightweight GPT-4 model\n",
    "    temperature=0,                  # Deterministic output (no randomness)\n",
    "    api_key=os.environ[\"OPEN_AI_SECRET_KEY\"]  # Pull your OpenAI key from environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c21e048-1a0f-43d5-853f-c0c56975e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbb626d-c1c0-416b-a536-2c9e8faf5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Markdown to: /home/santy/programming/python/langchain/mypdf.md\n"
     ]
    }
   ],
   "source": [
    "# 4) Convert each chunk → Markdown and merge\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for i, d in enumerate(chunks, start=1):\n",
    "        md = chain.invoke({\"chunk\": d.page_content})\n",
    "        f.write(md.rstrip() + \"\\n\\n\")  # spacer between chunks\n",
    "\n",
    "print(f\"Wrote Markdown to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c84fb-ab51-4603-acb1-f1973b0538d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
